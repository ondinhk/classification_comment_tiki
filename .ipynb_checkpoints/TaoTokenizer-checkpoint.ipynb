{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = \"./data/non_stop_word(3).json\"\n",
    "df = pd.read_json(path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xáo trộn dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127093</th>\n",
       "      <td>máy_ảnh quả to giống mình theo cảm_nhận riêng thì ăn cũng đc chứ không quá xuất_sắc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217268</th>\n",
       "      <td>cà_phê ngon phù_hợp cho buổi sáng bận_rộn giá sinh_viên nữa chứ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020111</th>\n",
       "      <td>hàng mới đẹp nguyên_vẹn lỗ lắp_ráp chuẩn lắp_ráp chuẩn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839131</th>\n",
       "      <td>đầu_tiên thì mình cảm_ơn tiki vì cách gói hàng vẫn luôn chất_lượng và giao hàng nhanh hơn dự_kiến đến thế về nội_dung của sách thì đây là cuốn chia làm hai phần về thơ tình và tản_văn những dòng t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300728</th>\n",
       "      <td>mới nhận chưa sử_dụng nhân_viên giao hàng tốt nhiệt_tình</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771204</th>\n",
       "      <td>giao hàng nhanh đóng_gói cẩn_thận sản_phẩm khá chất_lượng</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032209</th>\n",
       "      <td>giấy xấu hơn loại cũ giấy đen xài tới nửa bịch thì kéo ra 1 nùi luôn chứ không rời từng tấm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242048</th>\n",
       "      <td>hàng không tốt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564036</th>\n",
       "      <td>áo rất đẹp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852435</th>\n",
       "      <td>san pham nay dung duoc nhưng chua duoc tot_lam có gang nang cao chat luong hon nữa cũng ran hon nữa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1958552 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                         content  \\\n",
       "127093                                                                                                                       máy_ảnh quả to giống mình theo cảm_nhận riêng thì ăn cũng đc chứ không quá xuất_sắc   \n",
       "1217268                                                                                                                                          cà_phê ngon phù_hợp cho buổi sáng bận_rộn giá sinh_viên nữa chứ   \n",
       "1020111                                                                                                                                                   hàng mới đẹp nguyên_vẹn lỗ lắp_ráp chuẩn lắp_ráp chuẩn   \n",
       "1839131  đầu_tiên thì mình cảm_ơn tiki vì cách gói hàng vẫn luôn chất_lượng và giao hàng nhanh hơn dự_kiến đến thế về nội_dung của sách thì đây là cuốn chia làm hai phần về thơ tình và tản_văn những dòng t...   \n",
       "300728                                                                                                                                                  mới nhận chưa sử_dụng nhân_viên giao hàng tốt nhiệt_tình   \n",
       "...                                                                                                                                                                                                          ...   \n",
       "771204                                                                                                                                                 giao hàng nhanh đóng_gói cẩn_thận sản_phẩm khá chất_lượng   \n",
       "1032209                                                                                                              giấy xấu hơn loại cũ giấy đen xài tới nửa bịch thì kéo ra 1 nùi luôn chứ không rời từng tấm   \n",
       "242048                                                                                                                                                                                            hàng không tốt   \n",
       "564036                                                                                                                                                                                                áo rất đẹp   \n",
       "1852435                                                                                                      san pham nay dung duoc nhưng chua duoc tot_lam có gang nang cao chat luong hon nữa cũng ran hon nữa   \n",
       "\n",
       "         rate  \n",
       "127093      0  \n",
       "1217268     0  \n",
       "1020111     0  \n",
       "1839131     0  \n",
       "300728      0  \n",
       "...       ...  \n",
       "771204      0  \n",
       "1032209     1  \n",
       "242048      1  \n",
       "564036      0  \n",
       "1852435     0  \n",
       "\n",
       "[1958552 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=1, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable label & content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "content = df['content'][:1000]\n",
    "labels = df['rate'][:1000]\n",
    "print(content.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load PhoBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "# For transformers v4.x+:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
    "# max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = content.apply(lambda x: tokenizer.encode(\n",
    "    x, max_length=max_len, truncation=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding\n",
    "- Padding để đảm bảo input có độ dài như nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index user random\n",
    "index = 555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded: [   0  265  167  957 3628    2    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "len padded: (1000, 70)\n"
     ]
    }
   ],
   "source": [
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "print('padded:', padded[index])\n",
    "print('len padded:', padded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark\n",
    "- Đánh dấu các từ thêm vào = 0 để không tính vào quá trình lấy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention mask: [0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# get attention mask ( 0: not has word, 1: has word)\n",
    "attention_mask = np.where(padded == 0, 0, 1)\n",
    "print('attention mask:', attention_mask[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conver tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padd =  torch.Size([1000, 70])\n",
      "Attention_mask =  torch.Size([1000, 70])\n"
     ]
    }
   ],
   "source": [
    "padded = torch.tensor(padded).to(torch.long)\n",
    "print(\"Padd = \", padded.size())\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "print(\"Attention_mask = \", attention_mask.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    last_hidden_states = phobert(input_ids= padded, attention_mask=attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_features = last_hidden_states[0][:, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_features.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
