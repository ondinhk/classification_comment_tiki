{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sử dụng SVM kernal linear để train model\n",
    "- với test_size = 0.1\n",
    "- Tập train 126000, tập test 1400\n",
    "- Model với độ chính xác 81.92%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "\n",
    "def _save_pkl(path, obj):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "        \n",
    "def _load_pkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 768) (14000,)\n"
     ]
    }
   ],
   "source": [
    "path = './file_pkl/v_features.pkl'\n",
    "path_labels = './file_pkl/labels.pkl'\n",
    "path_data = './file_pkl/dataset.pkl'\n",
    "features = _load_pkl(path)\n",
    "labels = _load_pkl(path_labels)\n",
    "data = _load_pkl(path_data)\n",
    "print(features.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12600\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33860</th>\n",
       "      <td>hi tikimình mua 2 hộp nhưng 1 hộp bị móp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>giao hàng nhanh gói hàng chắc_chắn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19752</th>\n",
       "      <td>không như quảng_cáo tệ quá</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47147</th>\n",
       "      <td>hàng đóng_gói cẩn_thận nhưng giao hàng quá lâu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12055</th>\n",
       "      <td>đóng gói sản_phẩm cẩn_thận</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6367</th>\n",
       "      <td>hàng giao đúng ngàyđóng gói kĩ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51382</th>\n",
       "      <td>địa_chỉ giao hàng là hoàng ngọc hoà điện_thoại...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>sản_phẩm dùng tốt giá hợp_lý</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12387</th>\n",
       "      <td>luc dat hang thi có hang khuyen_mai sao luc gi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31986</th>\n",
       "      <td>mua 38 l mà giao 32 l không đúng như đã đặt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>sạch tốt bóng mịn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8754</th>\n",
       "      <td>rửa sạch không cần thêm mấy dung_dịch khác</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>mình chưa bao_giờ mua phải túi bỉm nào bị bẩn ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21008</th>\n",
       "      <td>tệ tiki cực_kỳ tệ tệ kinh_khủng</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51770</th>\n",
       "      <td>2 tháng mới nhận đuọc hàng</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>chất_lượng tốt giá hợp_lý giao hàng nhanh nhân...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>sản_phẩm gói okdùng tốttuy_nhiên tạo bọt không...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6777</th>\n",
       "      <td>hàng vận_chuyển nhanh mua đc giá sale nên ưng ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>giao hàng chậm quá tệ chả biết nói gì thêm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12383</th>\n",
       "      <td>đóng gói sản_phẩm cẩn_thận dịch nên giao hàng ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  rate\n",
       "33860           hi tikimình mua 2 hộp nhưng 1 hộp bị móp     1\n",
       "2756                  giao hàng nhanh gói hàng chắc_chắn     0\n",
       "19752                         không như quảng_cáo tệ quá     1\n",
       "47147  hàng đóng_gói cẩn_thận nhưng giao hàng quá lâu...     1\n",
       "12055                         đóng gói sản_phẩm cẩn_thận     0\n",
       "6367                      hàng giao đúng ngàyđóng gói kĩ     0\n",
       "51382  địa_chỉ giao hàng là hoàng ngọc hoà điện_thoại...     1\n",
       "1149                        sản_phẩm dùng tốt giá hợp_lý     0\n",
       "12387  luc dat hang thi có hang khuyen_mai sao luc gi...     1\n",
       "31986        mua 38 l mà giao 32 l không đúng như đã đặt     1\n",
       "7593                                   sạch tốt bóng mịn     0\n",
       "8754          rửa sạch không cần thêm mấy dung_dịch khác     0\n",
       "1625   mình chưa bao_giờ mua phải túi bỉm nào bị bẩn ...     1\n",
       "21008                    tệ tiki cực_kỳ tệ tệ kinh_khủng     1\n",
       "51770                         2 tháng mới nhận đuọc hàng     1\n",
       "3705   chất_lượng tốt giá hợp_lý giao hàng nhanh nhân...     0\n",
       "4382   sản_phẩm gói okdùng tốttuy_nhiên tạo bọt không...     0\n",
       "6777   hàng vận_chuyển nhanh mua đc giá sale nên ưng ...     0\n",
       "1732          giao hàng chậm quá tệ chả biết nói gì thêm     1\n",
       "12383  đóng gói sản_phẩm cẩn_thận dịch nên giao hàng ...     0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM kernel linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả train model, độ chính xác =  81.92857142857143 %\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel='linear', probability=True, gamma=0.125)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "sc = model.score(X_test, y_test)\n",
    "print('Kết quả train model, độ chính xác = ', sc*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_pkl('Model_SVM.pkl', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dự đoán bình luận\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from underthesea import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuẩn hóa input đầu vào\n",
    "- Loại bỏ dấu câu và ký tự đặc biết\n",
    "- Tách từ bằng word_tokenize \n",
    "- Chuyển input về dạng vector\n",
    "- Dùng phobert để trích đặc trưng\n",
    "- Trả về một array các đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_vn(row):\n",
    "    return word_tokenize(row, format=\"text\")\n",
    "\n",
    "\n",
    "path_file_acr = \"./TuDienVietTat/acronym_vi.txt\"\n",
    "acronyms_list = []\n",
    "with open(path_file_acr, 'r', encoding=\"utf8\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = re.sub('[\\n]', '', line)\n",
    "        acronyms_list.append(line.split('\\t'))\n",
    "\n",
    "\n",
    "def replace_acronyms(self, acronyms):\n",
    "    list_text = self.split(\" \")\n",
    "    for i in range(len(list_text)):\n",
    "        for j in range(len(acronyms)):\n",
    "            if(list_text[i] == acronyms[j][0]):\n",
    "                list_text[i] = acronyms[j][1]\n",
    "    self = \" \".join(list_text)\n",
    "    return self\n",
    "\n",
    "\n",
    "# Hàm chuẩn hoá câu\n",
    "def standardize_data(row):\n",
    "    # Xóa dấu chấm, phẩy, hỏi ở cuối câu\n",
    "    row = re.sub(r\"[\\.,\\?]+$-\", \"\", row)\n",
    "    row = re.sub('[\\n\\/]', '', row)\n",
    "    # Xóa tất cả dấu chấm, phẩy, chấm phẩy, chấm thang, ... trong câu\n",
    "    row = row.replace(\",\", \"\").replace(\".\", \"\") \\\n",
    "        .replace(\";\", \"\").replace(\"“\", \"\") \\\n",
    "        .replace(\":\", \"\").replace(\"”\", \"\") \\\n",
    "        .replace('\"', \"\").replace(\"'\", \"\") \\\n",
    "        .replace(\"!\", \"\").replace(\"?\", \"\") \\\n",
    "        .replace(\"-\", \"\").replace(\"?\", \"\") \\\n",
    "        .replace('*\\r?\\n*', '')\n",
    "\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    row = emoji_pattern.sub(r'', row)\n",
    "    row = row.strip().lower()\n",
    "    return row\n",
    "\n",
    "\n",
    "def feature_text(text):\n",
    "    max_len = 20\n",
    "    text = standardize_data(text)\n",
    "    text = replace_acronyms(text, acronyms=acronyms_list)\n",
    "    sentence = tokenizer_vn(text)\n",
    "    print(sentence)\n",
    "    tokenized = tokenizer.encode(sentence)\n",
    "    padded = np.array([tokenized + [0]*(max_len-len(tokenized))])\n",
    "    train_mask = np.where(padded == 0, 0, 1)\n",
    "    train_text = torch.tensor(padded).to(torch.long)\n",
    "    train_mask = torch.tensor(train_mask)\n",
    "    with torch.no_grad():\n",
    "        features = phobert(train_text, train_mask)\n",
    "    return features[0][:, 0, :].numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_comment(text):\n",
    "    features = feature_text(text)\n",
    "    sc = model.predict(features)\n",
    "    if(sc[0] == 0):\n",
    "        print(\"Tích cực\")\n",
    "    else:\n",
    "        print(\"Tiêu cực\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thời_gian vận_chuyển lâu sản_phẩm đóng_gói kém\n",
      "Tiêu cực\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Thời gian ship lâu, sản phẩm đóng gói kém\"\n",
    "pre_comment(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sản_phẩm tốt chất_lượng vận_chuyển nhanh đáng để mua\n",
      "Tích cực\n"
     ]
    }
   ],
   "source": [
    "text2 = \"Sản phẩm tốt chất lượng ship nhanh đáng để mua\"\n",
    "pre_comment(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tháng mới nhận đuọc hàng\n",
      "Tiêu cực\n"
     ]
    }
   ],
   "source": [
    "text3 = \"2 tháng mới nhận đuọc hàng\"\n",
    "pre_comment(text3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
