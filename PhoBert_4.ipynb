{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_pkl(path):\n",
    "  with open(path, 'rb') as f:\n",
    "    obj = pickle.load(f)\n",
    "  return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_x = './file_pkl/padding.pkl'\n",
    "path_y = './file_pkl/labels.pkl'\n",
    "padded = _load_pkl(path_x)\n",
    "labels = _load_pkl(path_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(padded, labels, test_size=0.2)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4680\n",
      "1300\n",
      "520\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYkoS300IPoY"
   },
   "source": [
    "# Mask\n",
    "- Đánh dấu các từ thêm vào = 0 để không tính vào quá trình lấy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random user\n",
    "index = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention mask: [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "val_mask mask: [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# get attention mask ( 0: not has word, 1: has word)\n",
    "train_mask = np.where(X_train == 0, 0, 1)\n",
    "val_mask = np.where(X_val == 0, 0, 1)\n",
    "print('attention mask:', train_mask[index])\n",
    "print('val_mask mask:', val_mask[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4680, 50)\n",
      "(4680, 50)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(train_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,   320,   574,  ...,     0,     0,     0],\n",
      "        [    0,   574,   119,  ...,     0,     0,     0],\n",
      "        [    0,    17, 28123,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    0,  2560,  2273,  ...,     0,     0,     0],\n",
      "        [    0,   574,   119,  ...,     0,     0,     0],\n",
      "        [    0,  2081,  5418,  ...,     0,     0,     0]])\n",
      "tensor([[0, 1, 1,  ..., 0, 0, 0],\n",
      "        [0, 1, 1,  ..., 0, 0, 0],\n",
      "        [0, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 1, 1,  ..., 0, 0, 0],\n",
      "        [0, 1, 1,  ..., 0, 0, 0],\n",
      "        [0, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "train_text = torch.tensor(X_train).to(torch.long)\n",
    "train_mask = torch.tensor(train_mask)\n",
    "print(train_text)\n",
    "print(train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy features dầu ra từ BERT\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = phobert(input_ids= train_text, attention_mask=train_mask)\n",
    "\n",
    "v_features = last_hidden_states[0][:, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_pkl(path, obj):\n",
    "  with open(path, 'wb') as f:\n",
    "    pickle.dump(obj, f)\n",
    "\n",
    "# Lưu lại các files\n",
    "_save_pkl('./file_pkl/v_features.pkl', v_features)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
